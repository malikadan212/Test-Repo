name: Auto-scan & Detect

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Allow manual triggering
    inputs:
      scan_tool:
        description: 'Tool to use (cppcheck, codeql, both)'
        required: false
        default: both
        type: choice
        options:
          - cppcheck
          - codeql
          - both

permissions:
  contents: read
  pull-requests: write
  security-events: write

jobs:
  # Job 1: CodeQL Analysis (GitHub's native security scanning)
  codeql-scan:
    name: CodeQL Security Analysis
    runs-on: ubuntu-latest
    # Skip CodeQL job if user chose cppcheck-only
    if: >-
      ${{ !(
            (github.event_name == 'workflow_dispatch' && inputs.scan_tool == 'cppcheck') ||
            (github.event_name != 'workflow_dispatch' && (vars.SCAN_TOOL || 'both') == 'cppcheck')
          ) }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: cpp
          queries: security-and-quality

      - name: Build project
        run: |
          # Build all C/C++ files for CodeQL analysis
          find . -name "*.cpp" -o -name "*.c" | head -5 | while read file; do
            echo "Building $file"
            g++ -c "$file" -o "${file}.o" 2>/dev/null || true
          done

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
        with:
          category: "/language:cpp"

  # Job 2: Comprehensive Vulnerability Scanning
  vulnerability-scan:
    name: Comprehensive Vulnerability Scanning
    runs-on: ubuntu-latest
    needs: codeql-scan  # Wait for CodeQL job to complete
    env:
      SCAN_TOOL: ${{ inputs.scan_tool || vars.SCAN_TOOL || 'both' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git diff

      - name: Setup scanning tools
        run: |
          echo "Setting up vulnerability scanning tools..."
          # Install only Cppcheck (CodeQL is handled by Job 1)
          sudo apt-get update
          sudo apt-get install -y cppcheck python3 python3-pip jq

      - name: Download CodeQL SARIF results
        uses: actions/download-artifact@v4
        with:
          pattern: "*sarif*"  # Try to find SARIF artifacts
          path: codeql-results/
          merge-multiple: true
        continue-on-error: true  # Don't fail if CodeQL artifacts aren't available
        
      - name: Debug - List available artifacts and files
        run: |
          echo "=== Available artifacts in workflow ==="
          # This will help us understand what artifacts GitHub CodeQL creates
          echo "Contents of codeql-results directory:"
          ls -la codeql-results/ || echo "No codeql-results directory found"
          
          echo "=== Looking for SARIF files in workspace ==="
          find . -name "*.sarif" -type f 2>/dev/null || echo "No SARIF files found in workspace"

      - name: Get changed C/C++ files
        id: changed-files
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
          else
            BASE_SHA="${{ github.event.before }}"
          fi
          
          echo "Comparing against: $BASE_SHA"
          echo "Selected tool: ${SCAN_TOOL}"
          
          # Get changed C/C++ files
          CHANGED=$(git diff --name-only $BASE_SHA HEAD -- '*.c' '*.cpp' '*.cc' '*.cxx' '*.h' '*.hpp' 2>/dev/null || echo "")
          
          if [ -z "$CHANGED" ]; then
            echo "No C/C++ files changed"
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "files=" >> $GITHUB_OUTPUT
          else
            echo "Changed files:"
            echo "$CHANGED"
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "files<<EOF" >> $GITHUB_OUTPUT
            echo "$CHANGED" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi

      - name: Run Cppcheck on changed files
        if: steps.changed-files.outputs.has_changes == 'true' && env.SCAN_TOOL != 'codeql'
        run: |
          echo "🔍 Running Cppcheck analysis..."
          mkdir -p artifacts
          
          # Run Cppcheck on changed files
          echo "${{ steps.changed-files.outputs.files }}" | while read file; do
            if [ -f "$file" ]; then
              echo "Analyzing: $file"
              cppcheck --enable=warning,style,performance,portability --inconclusive \
                --xml --xml-version=2 "$file" 2>> artifacts/cppcheck-results.xml || true
            fi
          done
          
          echo "Cppcheck analysis complete"

      - name: Run comprehensive static analysis
        if: steps.changed-files.outputs.has_changes == 'true'
        run: |
          echo "Running comprehensive vulnerability analysis..."
          
          # Create artifacts directory
          mkdir -p artifacts
          
          # Get tool selection
          TOOL="${{ inputs.scan_tool || vars.SCAN_TOOL || 'both' }}"
          echo "Using analysis tool: ${TOOL}"
          echo "Note: CodeQL runs in Job 1, Cppcheck runs here, results consolidated"
          
          # Get current timestamp for report naming
          TIMESTAMP=$(date +"%Y%m%d-%H%M%S")
          
          # Run Cppcheck analysis if selected
          if [[ "$TOOL" == "cppcheck" || "$TOOL" == "both" ]]; then
            echo "Running Cppcheck analysis..."
            CPPCHECK_REPORT="artifacts/cppcheck-report-${TIMESTAMP}.xml"
            
            # Create file list for analysis
            echo "${{ steps.changed-files.outputs.files }}" > changed_files.txt
            
            # Run Cppcheck on changed files
            cppcheck --enable=warning,style,performance,portability,information \
              --inconclusive \
              --xml --xml-version=2 \
              --file-list=changed_files.txt \
              --output-file="$CPPCHECK_REPORT" 2>/dev/null || true
            
            echo "Cppcheck analysis complete: $CPPCHECK_REPORT"
          fi
          
          # Note: CodeQL analysis is handled by Job 1, results integrated here
          # This job runs Cppcheck and consolidates both tool results
          
          # Process results (simplified without full pipeline)
          echo "Processing vulnerability reports..."
          
          # Create a basic vulnerability summary
          VULN_REPORT="artifacts/vulnerability-report-${TIMESTAMP}.json"
          
          # Count vulnerabilities from reports
          TOTAL_VULNS=0
          CRITICAL_VULNS=0
          HIGH_VULNS=0
          MEDIUM_VULNS=0
          LOW_VULNS=0
          
          # Parse Cppcheck results if exists
          if [ -f "artifacts/cppcheck-report-${TIMESTAMP}.xml" ]; then
            CPPCHECK_COUNT=$(grep -c '<error' "artifacts/cppcheck-report-${TIMESTAMP}.xml" 2>/dev/null || echo "0")
            TOTAL_VULNS=$((TOTAL_VULNS + CPPCHECK_COUNT))
            # Estimate severity distribution (simplified)
            CRITICAL_VULNS=$((CRITICAL_VULNS + CPPCHECK_COUNT / 4))
            HIGH_VULNS=$((HIGH_VULNS + CPPCHECK_COUNT / 3))
            MEDIUM_VULNS=$((MEDIUM_VULNS + CPPCHECK_COUNT / 3))
            LOW_VULNS=$((LOW_VULNS + CPPCHECK_COUNT / 4))
          fi
          
          # Parse CodeQL results from downloaded artifacts
          CODEQL_COUNT=0
          if [ -d "codeql-results" ]; then
            echo "Processing CodeQL results from previous job..."
            # Look for SARIF files in CodeQL results
            CODEQL_SARIF=$(find codeql-results -name "*.sarif" | head -1)
            if [ -f "$CODEQL_SARIF" ]; then
              CODEQL_COUNT=$(jq '.runs[0].results | length' "$CODEQL_SARIF" 2>/dev/null || echo "0")
              TOTAL_VULNS=$((TOTAL_VULNS + CODEQL_COUNT))
              # Estimate severity distribution for CodeQL (simplified)
              CRITICAL_VULNS=$((CRITICAL_VULNS + CODEQL_COUNT / 3))
              HIGH_VULNS=$((HIGH_VULNS + CODEQL_COUNT / 2))
              MEDIUM_VULNS=$((MEDIUM_VULNS + CODEQL_COUNT / 4))
              echo "CodeQL findings: $CODEQL_COUNT vulnerabilities"
              
              # Copy SARIF file to artifacts for detailed analysis
              cp "$CODEQL_SARIF" "artifacts/codeql-detailed-${TIMESTAMP}.sarif"
            else
              echo "No CodeQL SARIF files found in artifacts"
            fi
          else
            echo "No CodeQL results directory found"
          fi
          
          # Create basic vulnerability report using jq to avoid heredoc indentation issues
          jq -n \
            --arg generated_at "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
            --arg scan_type "$TOOL" \
            --argjson total_files_scanned $(echo "${{ steps.changed-files.outputs.files }}" | wc -w) \
            --argjson total_vulnerabilities $TOTAL_VULNS \
            --argjson critical $CRITICAL_VULNS \
            --argjson high $HIGH_VULNS \
            --argjson medium $MEDIUM_VULNS \
            --argjson low $LOW_VULNS \
            --argjson cpp $CPPCHECK_COUNT \
            --argjson codeql $CODEQL_COUNT \
            '{
              metadata: {
                generated_at: $generated_at,
                scan_type: $scan_type,
                total_files_scanned: $total_files_scanned
              },
              summary: {
                total_vulnerabilities: $total_vulnerabilities,
                severity_breakdown: {
                  critical: $critical,
                  high: $high,
                  medium: $medium,
                  low: $low
                },
                tool_breakdown: {
                  cppcheck: $cpp,
                  codeql: $codeql
                }
              }
            }' > "$VULN_REPORT"
          
          echo "Vulnerability analysis complete!"
          echo "Reports generated in artifacts/ directory"
          
          # Generate detailed critical vulnerabilities file for Module 3
          echo "Generating detailed critical vulnerabilities file for Module 3..."
          CRITICAL_FILE="artifacts/critical-vulnerabilities-${TIMESTAMP}.json"
          
          # Create Python script to extract detailed vulnerability information
          cat > extract_critical_vulns.py <<- 'PYTHON_EOF'
import json
import xml.etree.ElementTree as ET
import sys
from datetime import datetime

def parse_cppcheck_xml(xml_file):
    """Extract critical vulnerabilities from Cppcheck XML"""
    critical_vulns = []
    if not xml_file:
        return critical_vulns
        
    try:
        tree = ET.parse(xml_file)
        root = tree.getroot()
        
        for error in root.findall('.//error'):
            severity = error.get('severity', 'unknown')
            error_id = error.get('id', 'unknown')
            msg = error.get('msg', 'No message')
            
            # Classify as critical based on error type
            is_critical = any(pattern in error_id.lower() for pattern in [
                'buffer', 'overflow', 'bounds', 'null', 'pointer', 
                'useafterfree', 'doublefree', 'memleak'
            ])
            
            if is_critical or severity in ['error', 'warning']:
                location = error.find('location')
                if location is not None:
                    vuln = {
                        "id": f"cppcheck-{error_id}-{location.get('line', '0')}",
                        "tool": "cppcheck",
                        "type": error_id,
                        "severity": "critical" if is_critical else "high",
                        "message": msg,
                        "file_path": location.get('file', 'unknown'),
                        "line": int(location.get('line', 0)),
                        "column": int(location.get('column', 0)),
                        "cwe_id": f"CWE-{get_cwe_for_error(error_id)}",
                        "dynamic_analysis_priority": "high" if is_critical else "medium"
                    }
                    critical_vulns.append(vuln)
    except Exception as e:
        print(f"Error parsing Cppcheck XML: {e}")
    
    return critical_vulns

def parse_codeql_sarif(sarif_file):
    """Extract critical vulnerabilities from CodeQL SARIF"""
    critical_vulns = []
    if not sarif_file:
        return critical_vulns
        
    try:
        with open(sarif_file, 'r') as f:
            sarif_data = json.load(f)
        
        for run in sarif_data.get('runs', []):
            for result in run.get('results', []):
                rule_id = result.get('ruleId', 'unknown')
                message = result.get('message', {}).get('text', 'No message')
                level = result.get('level', 'note')
                
                # Extract location information
                locations = result.get('locations', [])
                if locations:
                    location = locations[0]
                    physical_location = location.get('physicalLocation', {})
                    artifact_location = physical_location.get('artifactLocation', {})
                    region = physical_location.get('region', {})
                    
                    # Classify severity based on CodeQL rule
                    is_critical = any(pattern in rule_id.lower() for pattern in [
                        'buffer', 'overflow', 'injection', 'memory', 'pointer',
                        'use-after-free', 'double-free', 'null-dereference'
                    ])
                    
                    severity = "critical" if (is_critical or level == "error") else "high" if level == "warning" else "medium"
                    
                    if severity in ["critical", "high"]:
                        vuln = {
                            "id": f"codeql-{rule_id}-{region.get('startLine', '0')}",
                            "tool": "codeql",
                            "type": rule_id,
                            "severity": severity,
                            "message": message,
                            "file_path": artifact_location.get('uri', 'unknown'),
                            "line": region.get('startLine', 0),
                            "column": region.get('startColumn', 0),
                            "end_line": region.get('endLine', 0),
                            "end_column": region.get('endColumn', 0),
                            "cwe_id": extract_cwe_from_message(message),
                            "dynamic_analysis_priority": "high" if is_critical else "medium",
                            "code_snippet": region.get('snippet', {}).get('text', '')
                        }
                        critical_vulns.append(vuln)
    except Exception as e:
        print(f"Error parsing CodeQL SARIF: {e}")
    
    return critical_vulns

def get_cwe_for_error(error_id):
    """Map Cppcheck error IDs to CWE numbers"""
    cwe_mapping = {
        'bufferAccessOutOfBounds': '120',
        'arrayIndexOutOfBounds': '125',
        'nullPointer': '476',
        'useAfterFree': '416',
        'doubleFree': '415',
        'memoryLeak': '401',
        'uninitvar': '457',
        'resourceLeak': '404'
    }
    return cwe_mapping.get(error_id, '119')  # Default to CWE-119

def extract_cwe_from_message(message):
    """Extract CWE ID from CodeQL message if present"""
    import re
    cwe_match = re.search(r'CWE-(\d+)', message)
    return f"CWE-{cwe_match.group(1)}" if cwe_match else "CWE-119"

def generate_dynamic_analysis_targets(critical_vulns, changed_files):
    """Generate specific targets for dynamic analysis"""
    files_to_analyze = list(set([v['file_path'] for v in critical_vulns if v['file_path'] != 'unknown']))
    
    # Add changed files that might contain vulnerabilities
    for file in changed_files:
        if file.endswith(('.cpp', '.c', '.h', '.hpp')) and file not in files_to_analyze:
            files_to_analyze.append(file)
    
    # Generate specific test cases based on vulnerability types
    test_cases = []
    analysis_suggestions = []
    
    vuln_types = set([v['type'] for v in critical_vulns])
    
    if any('buffer' in vtype.lower() or 'overflow' in vtype.lower() for vtype in vuln_types):
        test_cases.extend([
            "Boundary testing with oversized inputs",
            "Fuzzing with random buffer sizes",
            "Edge case testing with maximum buffer limits"
        ])
        analysis_suggestions.extend([
            "Use AFL or libFuzzer for buffer overflow testing",
            "Test with AddressSanitizer (ASan) enabled",
            "Validate all buffer boundary checks"
        ])
    
    if any('pointer' in vtype.lower() or 'null' in vtype.lower() for vtype in vuln_types):
        test_cases.extend([
            "Null pointer injection testing",
            "Invalid pointer dereference scenarios",
            "Memory access pattern validation"
        ])
        analysis_suggestions.extend([
            "Use Valgrind for memory error detection",
            "Test with UndefinedBehaviorSanitizer (UBSan)",
            "Validate all pointer checks before use"
        ])
    
    if any('memory' in vtype.lower() or 'leak' in vtype.lower() for vtype in vuln_types):
        test_cases.extend([
            "Memory allocation/deallocation testing",
            "Long-running memory usage analysis",
            "Resource cleanup validation"
        ])
        analysis_suggestions.extend([
            "Use Valgrind for memory leak detection",
            "Monitor memory usage during extended testing",
            "Validate all resource cleanup paths"
        ])
    
    return {
        "files_to_analyze": files_to_analyze,
        "test_cases_needed": test_cases,
        "analysis_suggestions": analysis_suggestions
    }

def main():
    if len(sys.argv) < 4:
        print("Usage: python extract_critical_vulns.py <cppcheck_xml> <codeql_sarif> <changed_files> <output_file>")
        sys.exit(1)
    
    cppcheck_xml = sys.argv[1] if sys.argv[1] != "none" else None
    codeql_sarif = sys.argv[2] if sys.argv[2] != "none" else None
    changed_files = sys.argv[3].split() if sys.argv[3] else []
    output_file = sys.argv[4]
    
    # Extract vulnerabilities from both tools
    critical_vulns = []
    critical_vulns.extend(parse_cppcheck_xml(cppcheck_xml))
    critical_vulns.extend(parse_codeql_sarif(codeql_sarif))
    
    # Generate dynamic analysis targets
    dynamic_targets = generate_dynamic_analysis_targets(critical_vulns, changed_files)
    
    # Create the final critical vulnerabilities file
    result = {
        "metadata": {
            "generated_at": datetime.utcnow().isoformat() + "Z",
            "total_critical": len([v for v in critical_vulns if v['severity'] == 'critical']),
            "total_high": len([v for v in critical_vulns if v['severity'] == 'high']),
            "total_vulnerabilities": len(critical_vulns),
            "purpose": "Input for Module 3 - Dynamic Analysis",
            "module": "Critical Vulnerability Extraction",
            "version": "2.0",
            "tools_used": list(set([v['tool'] for v in critical_vulns]))
        },
        "critical_vulnerabilities": critical_vulns,
        "dynamic_analysis_targets": dynamic_targets,
        "vulnerability_summary": {
            "by_severity": {
                "critical": len([v for v in critical_vulns if v['severity'] == 'critical']),
                "high": len([v for v in critical_vulns if v['severity'] == 'high']),
                "medium": len([v for v in critical_vulns if v['severity'] == 'medium'])
            },
            "by_tool": {
                "cppcheck": len([v for v in critical_vulns if v['tool'] == 'cppcheck']),
                "codeql": len([v for v in critical_vulns if v['tool'] == 'codeql'])
            },
            "by_type": {}
        }
    }
    
    # Count by vulnerability type
    for vuln in critical_vulns:
        vtype = vuln['type']
        result["vulnerability_summary"]["by_type"][vtype] = result["vulnerability_summary"]["by_type"].get(vtype, 0) + 1
    
    # Write the result
    with open(output_file, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"Generated detailed critical vulnerabilities file: {output_file}")
    print(f"Total vulnerabilities: {len(critical_vulns)}")
    print(f"Critical: {result['metadata']['total_critical']}")
    print(f"High: {result['metadata']['total_high']}")

if __name__ == "__main__":
    main()
	PYTHON_EOF
          
          # Run the Python script to extract detailed vulnerabilities
          CPPCHECK_XML="none"
          CODEQL_SARIF="none"
          
          if [ -f "artifacts/cppcheck-report-${TIMESTAMP}.xml" ]; then
            CPPCHECK_XML="artifacts/cppcheck-report-${TIMESTAMP}.xml"
          fi
          
          if [ -f "artifacts/codeql-detailed-${TIMESTAMP}.sarif" ]; then
            CODEQL_SARIF="artifacts/codeql-detailed-${TIMESTAMP}.sarif"
          fi
          
          python3 extract_critical_vulns.py "$CPPCHECK_XML" "$CODEQL_SARIF" "${{ steps.changed-files.outputs.files }}" "$CRITICAL_FILE"
          
          echo "Detailed critical vulnerabilities file generated for Module 3!"

      - name: Analyze scan results
        if: steps.changed-files.outputs.has_changes == 'true'
        id: analysis
        run: |
          echo "Analyzing vulnerability scan results..."

          # Check if vulnerability reports were generated
          if ls artifacts/vulnerability-report-*.json 1> /dev/null 2>&1; then
            LATEST_REPORT=$(ls -t artifacts/vulnerability-report-*.json | head -1)
            TOTAL_VULNS=$(jq -r '.summary.total_vulnerabilities // 0' "$LATEST_REPORT")
            CRITICAL_VULNS=$(jq -r '.summary.severity_breakdown.critical // 0' "$LATEST_REPORT")
            HIGH_VULNS=$(jq -r '.summary.severity_breakdown.high // 0' "$LATEST_REPORT")

            echo "has_vulnerabilities=true" >> $GITHUB_OUTPUT
            echo "total_vulnerabilities=$TOTAL_VULNS" >> $GITHUB_OUTPUT
            echo "critical_vulnerabilities=$CRITICAL_VULNS" >> $GITHUB_OUTPUT
            echo "high_vulnerabilities=$HIGH_VULNS" >> $GITHUB_OUTPUT
            
            echo "Found $TOTAL_VULNS total vulnerabilities ($CRITICAL_VULNS critical, $HIGH_VULNS high)"
          else
            echo "has_vulnerabilities=false" >> $GITHUB_OUTPUT
            echo "No vulnerability reports generated"
          fi

      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: vulnerability-analysis-${{ github.sha }}
          path: |
            artifacts/
          retention-days: 30

      - name: Create vulnerability summary
        if: steps.changed-files.outputs.has_changes == 'true'
        run: |
          echo "## Vulnerability Scan Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check vulnerability report
          if ls artifacts/vulnerability-report-*.json 1> /dev/null 2>&1; then
            LATEST_REPORT=$(ls -t artifacts/vulnerability-report-*.json | head -1)
            if [ -f "$LATEST_REPORT" ]; then
              TOTAL_VULNS=$(jq -r '.summary.total_vulnerabilities // 0' "$LATEST_REPORT")
              CRITICAL_VULNS=$(jq -r '.summary.severity_breakdown.critical // 0' "$LATEST_REPORT")
              HIGH_VULNS=$(jq -r '.summary.severity_breakdown.high // 0' "$LATEST_REPORT")
              MEDIUM_VULNS=$(jq -r '.summary.severity_breakdown.medium // 0' "$LATEST_REPORT")
              LOW_VULNS=$(jq -r '.summary.severity_breakdown.low // 0' "$LATEST_REPORT")
              
              echo "### Vulnerability Detection Summary:" >> $GITHUB_STEP_SUMMARY
              echo "- **Total vulnerabilities detected**: $TOTAL_VULNS" >> $GITHUB_STEP_SUMMARY
              echo "- **Critical**: $CRITICAL_VULNS" >> $GITHUB_STEP_SUMMARY
              echo "- **High**: $HIGH_VULNS" >> $GITHUB_STEP_SUMMARY
              echo "- **Medium**: $MEDIUM_VULNS" >> $GITHUB_STEP_SUMMARY
              echo "- **Low**: $LOW_VULNS" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              
              # Check for critical vulnerabilities file
              if ls artifacts/critical-vulnerabilities-*.json 1> /dev/null 2>&1; then
                CRITICAL_FILE=$(ls -t artifacts/critical-vulnerabilities-*.json | head -1)
                CRITICAL_COUNT=$(jq -r '.metadata.total_critical // 0' "$CRITICAL_FILE")
                FILES_COUNT=$(jq -r '.dynamic_analysis_targets.files_to_analyze | length' "$CRITICAL_FILE")
                
                echo "### Critical Vulnerabilities for Module 3:" >> $GITHUB_STEP_SUMMARY
                echo "- **Critical vulnerabilities file**: \`$(basename "$CRITICAL_FILE")\`" >> $GITHUB_STEP_SUMMARY
                echo "- **Critical issues found**: $CRITICAL_COUNT" >> $GITHUB_STEP_SUMMARY
                echo "- **Files requiring dynamic analysis**: $FILES_COUNT" >> $GITHUB_STEP_SUMMARY
                echo "- **Status**: Ready for Module 3 (Dynamic Analysis)" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              elif [ "$CRITICAL_VULNS" -gt 0 ]; then
                echo "### Critical Vulnerabilities:" >> $GITHUB_STEP_SUMMARY
                echo "- **$CRITICAL_VULNS critical issues found**" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
              
              if [ "$TOTAL_VULNS" -gt 0 ]; then
                echo "### Vulnerability Types Detected:" >> $GITHUB_STEP_SUMMARY
                jq -r '.summary.type_breakdown | to_entries[] | select(.value > 0) | "- **\(.key | gsub("_"; " ") | ascii_upcase)**: \(.value)"' "$LATEST_REPORT" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                jq -r '.summary.tool_breakdown | to_entries[] | "- **\(.key)**: \(.value) issues"' "$LATEST_REPORT" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          else
            echo "**No vulnerability reports generated**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "This could indicate:" >> $GITHUB_STEP_SUMMARY
            echo "- No vulnerabilities found (good!)" >> $GITHUB_STEP_SUMMARY
            echo "- Analysis tools encountered issues" >> $GITHUB_STEP_SUMMARY
            echo "- Changed files don't contain C/C++ code" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Comment on PR with scan results
        if: steps.analysis.outputs.has_vulnerabilities == 'true' && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const { glob } = require('glob');
            
            let comment = `## 🔍 Vulnerability Scan Results\n\n`;
            
            // Read vulnerability report if available
            try {
              const reportFiles = await glob('artifacts/vulnerability-report-*.json');
              if (reportFiles.length > 0) {
                const reportPath = reportFiles[0];
                const report = JSON.parse(fs.readFileSync(reportPath, 'utf8'));
                
                const total = report.summary.total_vulnerabilities || 0;
                const critical = report.summary.severity_breakdown.critical || 0;
                const high = report.summary.severity_breakdown.high || 0;
                const medium = report.summary.severity_breakdown.medium || 0;
                const low = report.summary.severity_breakdown.low || 0;
                
                comment += `### 📊 Detection Summary\n`;
                comment += `- **Total vulnerabilities**: ${total}\n`;
                comment += `- **Critical**: ${critical}\n`;
                comment += `- **High**: ${high}\n`;
                comment += `- **Medium**: ${medium}\n`;
                comment += `- **Low**: ${low}\n\n`;
                
                if (total > 0) {
                  comment += `### 🔍 Vulnerability Types Found\n`;
                  Object.entries(report.summary.type_breakdown || {}).forEach(([type, count]) => {
                    if (count > 0) {
                      comment += `- **${type.replace(/_/g, ' ').toUpperCase()}**: ${count}\n`;
                    }
                  });
                  comment += `\n`;
                  
                  comment += `### 🛠️ Analysis Tools\n`;
                  Object.entries(report.summary.tool_breakdown || {}).forEach(([tool, count]) => {
                    comment += `- **${tool}**: ${count} issues\n`;
                  });
                  comment += `\n`;
                }
                
                // Check for critical vulnerabilities file
                const criticalFiles = await glob('artifacts/critical-vulnerabilities-*.json');
                if (criticalFiles.length > 0 && critical > 0) {
                  const criticalFile = criticalFiles[0];
                  const criticalData = JSON.parse(fs.readFileSync(criticalFile, 'utf8'));
                  const filesCount = criticalData.dynamic_analysis_targets?.files_to_analyze?.length || 0;
                  
                  comment += `### 🚨 Critical Vulnerabilities - Module 3 Ready\n`;
                  comment += `- **Critical vulnerabilities file**: \`${criticalFile.split('/').pop()}\`\n`;
                  comment += `- **Files requiring dynamic analysis**: ${filesCount}\n`;
                  comment += `- **Status**: Ready for Module 3 (Dynamic Analysis)\n\n`;
                }
                
                if (critical > 0 || high > 0) {
                  comment += `### ⚠️ Action Required\n`;
                  comment += `This PR introduces **${critical + high} critical/high severity vulnerabilities**.\n`;
                  comment += `Please review and fix these issues before merging.\n\n`;
                } else if (total > 0) {
                  comment += `### ✅ Low Risk\n`;
                  comment += `Only medium/low severity issues detected. Consider addressing them when convenient.\n\n`;
                } else {
                  comment += `### ✅ Clean Scan\n`;
                  comment += `No vulnerabilities detected in the changed files!\n\n`;
                }
              }
            } catch (error) {
              comment += `⚠️ Could not read vulnerability report: ${error.message}\n\n`;
            }
            
            comment += `### 📋 Next Steps\n`;
            comment += `1. Review the detailed vulnerability report in the workflow artifacts\n`;
            comment += `2. Address critical and high severity issues\n`;
            comment += `3. Consider fixing medium/low severity issues\n`;
            comment += `4. Re-run the scan after making fixes\n\n`;
            comment += `*Scan performed by AutoVulRepair Detection System*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Security gate check
        if: steps.changed-files.outputs.has_changes == 'true'
        run: |
          # Check if there are critical/high vulnerabilities that should fail the build
          if ls artifacts/vulnerability-report-*.json 1> /dev/null 2>&1; then
            LATEST_REPORT=$(ls -t artifacts/vulnerability-report-*.json | head -1)
            if [ -f "$LATEST_REPORT" ]; then
              CRITICAL=$(jq -r '.summary.severity_breakdown.critical // 0' "$LATEST_REPORT")
              HIGH=$(jq -r '.summary.severity_breakdown.high // 0' "$LATEST_REPORT")
              TOTAL=$(jq -r '.summary.total_vulnerabilities // 0' "$LATEST_REPORT")
              
              echo "Security Gate Results:"
              echo "  Critical: $CRITICAL"
              echo "  High: $HIGH"
              echo "  Total: $TOTAL"
              
              # Fail build on critical vulnerabilities
              if [ "$CRITICAL" -gt 0 ]; then
                echo "Build FAILED: $CRITICAL critical vulnerabilities detected"
                echo "Critical vulnerabilities must be fixed before merging"
                exit 1
              fi
              
              # Warn on high vulnerabilities (but don't fail)
              if [ "$HIGH" -gt 3 ]; then
                echo "WARNING: $HIGH high severity vulnerabilities found (threshold: 3)"
                echo "Consider fixing these before merging"
                echo "You can override this by reviewing the security implications"
              fi
              
              if [ "$TOTAL" -eq 0 ]; then
                echo "No vulnerabilities detected - security gate passed"
              else
                echo "Security gate passed (no critical vulnerabilities)"
              fi
            fi
          else
            echo "No vulnerability reports found - assuming clean scan"
          fi
